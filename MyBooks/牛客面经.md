# 面经总结

## 一、基本语言

### 1关键字

#### 1.0 ==static==关键字作用(链接属性、存储类型)

**1. 全局静态变量**

> 在**全局变量前加上关键字static**，全局变量就定义成一个全局静态变量.
>
> **静态存储区**，在整个程序运行期间一直存在。
>
> 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）；
>
> 作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。（**连接属性intern**）

**2.局部静态变量**

> 在局部变量之前加上关键字static，局部变量就成为一个局部静态变量。
>
> 内存中的位置：静态存储区
>
> 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）；
>
> 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变；

**3. 静态函数**

> 在函数返回类型前加static，函数就定义为**静态函数**。函数的定义和声明在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。
>
> 函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突；
>
> warning：不要再头文件中声明static的全局函数(头文件是给其他文件用的，链接属性应该放extern的声明)，不要在cpp内声明非static的全局函数（cpp文件用写函数定义，extern的函数不要在这声明，static的函数声明不要放头文件就放cpp），如果你要在多个cpp中复用该函数，就把它的声明提到头文件里去，否则cpp内部声明需加上static修饰；

**4. 类的静态成员**

>  ==在类中，静态成员可以实现多个对象之间的数据共享==，并且使用静态数据成员还不会破坏隐藏的原则，即保证了安全性。因此，静态成员是类的所有对象中共享的成员，而不是某个对象的成员。**对多个对象来说，静态数据成员只存储一处，供所有对象共用**

**5. 类的静态函数**

> 静态成员函数和静态数据成员一样，它们都**属于类**的静态成员，它们都不是对象成员。因此，对静态成员的**引用不需要用对象名**。

**静态变量什么时候初始化**

静态变量存储在虚拟地址空间的数据段和bss段，C语言中其在代码执行之前初始化，属于编译期初始化。而C++中由于引入对象，对象生成必须调用构造函数，因此C++规定全局或局部静态对象当且仅当对象首次用到时进行构造



#### 1.1 **extern关键字作用**

1 **基本解释**：extern可以置于变量或者函数前，以标示变量或者函数的定义在别的文件中，提示编译器遇到此变量和函数时在其他模块中寻找其定义。此外extern也可用来进行链接指定。

​      也就是说extern有两个作用，第一个,当它与"C"一起连用时，如: extern "C" void fun(int a, int b);则告诉编译器在编译fun这个函数名时按着C的规则去翻译相应的函数名而不是C++的，C++的规则在翻译这个函数名时会把fun这个名字变得面目全非，因为C++支持函数的重载
​    第二，当extern不与"C"在一起修饰变量或函数时，如在头文件中: extern int g_Int; 它的作用就是声明函数或全局变量的作用范围的关键字，其声明的函数和变量可以在本模块活其他模块中使用，记住它是一个声明不是定义!

1. extern声明变量在在外部定义？

2. extern修饰函数？

   > 答案与分析：
   > 　　如果函数的声明中带有关键字extern，仅仅是暗示这个函数可能在别的源文件里定义，没有其它作用。即下述两个函数声明没有明显的区别：
   > extern int f(); 和int f();
   > 　　当然，这样的用处还是有的，就是在程序中取代include “*.h”来声明函数，在一些复杂的项目中，我比较习惯在所有的函数声明前添加extern修饰。关于这样做的原因和利弊可见下面的这个例子：“用extern修饰的全局变量”
   >
   > 
   >
   > 当函数提供方单方面修改函数原型时，如果使用方不知情继续沿用原来的extern申明，这样编译时编译器不会报错。但是在运行过程中，因为少了或者多了输入参数，往往会照成系统错误，这种情况应该如何解决？
   > 　　答案与分析：
   > 　　目前业界针对这种情况的处理没有一个很完美的方案，通常的做法是提供方在自己的xxx_pub.h中提供对外部接口的声明，然后调用方include该头文件，从而省去extern这一步。以避免这种错误。
   > 　　宝剑有双锋，对extern的应用，不同的场合应该选择不同的做法。

3. extern C的作用？用法？

   

#### 1.2**volatile是干啥的**

1. 访问寄存器要比访问内存要块，因此CPU会优先访问该数据在寄存器中的存储结果，但是内存中的数据可能已经发生了改变，而寄存器中还保留着原来的结果。为了避免这种情况的发生将该变量声明为volatile，告诉CPU每次都从内存去读取数据。 
2. 一个参数可以即是const又是volatile的吗？可以，一个例子是只读状态寄存器，是volatile是因为它可能被意想不到的被改变，是const告诉程序不应该试图去修改他。

#### 1.3const

**const主要作用：**

（1）可以定义const常量，具有不可变性。 
例如：const int Max=100; Max++会产生错误; 
（2）便于进行类型检查，使编译器对处理内容有更多了解，消除了一些隐患。
例如： void f(const int i) { .........} 编译器就会知道i是一个常量，不允许修改； 
（3）可以避免意义模糊的数字出现，同样可以很方便地进行参数的调整和修改。 同宏定义一样，可以做到不变则已，一变都变！如（1）中，如果想修改Max的内容，只需要：const int Max=you want;即可！(有错，这样不能修改，会报重复定义的错误)

（4）可以保护被修饰的东西，防止意外的修改，增强程序的健壮性。 还是上面的例子，如果在函数体内修改了i，编译器就会报错； 
例如： void f(const int i) { i=10;//error! } 

 （5） 可以节省空间，避免不必要的内存分配。 例如： 
#define PI 3.14159 //常量宏 
const double Pi=3.14159; //此时并未将Pi放入RAM中 ...... 
double i=Pi; //此时为Pi分配内存，以后不再分配！ 
double I=PI; //编译期间进行宏替换，分配内存 
double j=Pi; //没有内存分配 
double J=PI; //再进行宏替换，又一次分配内存！ 
　　const定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是像#define一样给出的是立即数，所以，const定义的常量在程序运行过程中只有一份拷贝，而#define定义的常量在内存中有若干份拷贝。 
　　（6） 提高了效率。 
       编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。

#### 1.4inline

- **内联函数有什么优点？内联函数与宏定义的区别？**

1. 宏定义在预编译的时候就会进行宏替换； 
2. 内联函数在编译阶段，在调用内联函数的地方进行替换，减少了函数的调用过程，但是使得编译文件变大。因此，内联函数适合简单函数，对于复杂函数，即使定义了内联编译器可能也不会按照内联的方式进行编译。 
3. 内联函数相比宏定义更安全，内联函数可以检查参数，而宏定义只是简单的文本替换。因此推荐使用内联函数，而不是宏定义。 
4. 使用宏定义函数要特别注意给所有单元都加上括号，#define MUL(a, b) a  *b，这很危险，正确写法：#define MUL(a, b) ((a)*  (b))



### 2 说一下==C++和C的区别==

**设计思想上：**

> C++是面向对象的语言，而C是面向过程的结构化编程语言

**语法上：**

> C++具有封装、继承和多态三种特性
>
> C++相比C，增加多许多类型安全的功能，比如强制类型转换。
>
> C++支持范式编程，比如模板类、函数模板等

**具体细节：**

> **C89标准的C语言不支持函数默认值，C++支持函数默认值，且需要遵循从右向左赋初始值。** int  fun(int a ,int b = 10);
>
> **C语言不存在函数重载，C++根据函数名参数个数参数类型判断重载，属于静多态，必须同一作用域下才叫重载。**
>
> > 静多态：函数重载，函数模板
>
> > 动多态（运行时的多态）：继承中的多态（虚函数）。
>
> **C中的const叫只读变量，只是无法做左值的变量；C++中的const是真正的常量，但也有可能退化成c语言的常量，默认生成local符号。**
>
> **引用底层就是指针，使用时会直接解引用，可以配合const对一个立即数进行引用。**

### 3、c++中四种==cast转换==

C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast

1、const_cast

> 用于将const变量转为非const

2、static_cast(类比C中常规强转)

> ==用于各种隐式转换==，比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知；

3、dynamic_cast

> 用于动态类型转换。==只能用于含有虚函数的类，==用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。
>
> 向上转换：指的是子类向基类的转换
>
> 向下转换：指的是基类向子类的转换
>
> 它通过判断在执行到该语句的时候**变量的运行时类型**和**要转换的类型**是否相同来判断是否能够进行向下转换。

4、reinterpret_cast

> 几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用；

5、为什么不使用C的强制转换？

> C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。

### 4、C/C++ 中==指针==和==引用==的区别？

> 1.指针有自己的一块**空间**，而引用只是一个别名；
>
> 2.使用**sizeof**看一个指针的大小是4，而引用则是被引用对象的大小；
>
> 3.指针可以被**初始化**为NULL，而引用必须被初始化且必须是一个已有对象 的引用；
>
> 4.作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引 用的修改都会改变引用所指向的对象；
>
> 5.可以有**const**指针，但是没有const引用；(引用常量不存在，没有int& const p，常量引用是存在的cosnt int &p)
>
> 6.指针在使用中可以指向其它对象，但是引用只能是一个对象的引用，不能 被**改变**；
>
> 7.指针可以有多级指针（**p），而引用至于一级；
>
> 8.指针和引用使用++运算符的意义不一样；
>
> 9.如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露。

### 5、C++中的==智能指针==

C++里面的四个智能指针: auto_ptr, shared_ptr, weak_ptr, **unique_ptr** 其中后三个是c++11支持，并且第一个已经被11弃用

> p2 = p1; //auto_ptr不会报错.
>
> 此时不会报错，p2剥夺了p1的所有权，但是当程序运行时访问p1将会报错。所以auto_ptr的缺点是：存在潜在的内存崩溃问题！

weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的构造和析构不会引起引用记数的增加或减少。weak_ptr是用来解决shared_ptr相互引用时的死锁问题

为什么要使用智能指针：

> 智能指针的作用是管理一个指针，因为存在以下这种情况：**申请的空间在函数结束时忘记释放，造成内存泄漏**。使用智能指针可以很大程度上的避免这个问题，因为**智能指针就是一个类，当超出了类的作用域是，类会自动调用析构函数**，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。



### 6、==数组==和==指针==的区别

> 数组：数组是**用于储存多个相同类型数据的集合**。
>
> 指针：指针相当于一个**变量**，但是它和不同变量不一样，它存放的**是其它变量在内存中的地址**。
>
> 区别：
>
> •    **赋值**：同类型指针变量可以相互赋值，数组不行，只能一个一个元素的赋值或拷贝
>
> •    **存储方式**：数组：数组在内存中是连续存放的，开辟一块连续的内存空间。数组是根据数组的下进行访问的，多维数组在内存中是按照一维数组存储的，只是在逻辑上是多维的。指针：指针很灵活，它可以指向任意类型的数据。指针的类型说明了它所指向地址空间的内存。
>
> •    **求sizeof**：数组所占存储空间的内存：sizeof（数组名），数组的大小：sizeof（数组名）/sizeof（数据类型）。在32位平台下，无论指针的类型是什么，sizeof（指针名）都是4，在64位平台下，无论指针的类型是什么，sizeof（指针名）都是8。
>
> •    初始化方式不同。
>
> •    **传参方式**：数组传参时，会退化为指针，C语言将数组的传参进行了退化。将整个数组拷贝一份传入函数时，将数组名看做常量指针，传数组首元素的地址。一级指针传参可以接受的参数类型：（1）可以是一个整形指针 （2）可以是整型变量地址 （3）可以是一维整型数组数组名；当函数参数部分是二级指针时，可以接受的参数类型：（1）二级指针变量（2）一级指针变量地址（3）一维指针数组的数组名

### 7、为什么==析构函数必须是虚函数==？为什么C++默认的析构函数不是虚函数

> 将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，**防止内存泄漏**。



> C++默认的析构函数不是虚函数是**因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存**。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。

### 8、==析构函数==的作用

1. 作用：对象消亡时，自动被调用，用来释放对象占用的空间 
2. 特点:    (1) 名字与类名相同    (2) 在前面需要加上"~"    (3) 无参数，无返回值    (4) 一个类最多只有一个析构函数    (5) 不显示定义析构函数会调用缺省析构函数

#### 8.1**==纯虚函数==如何定义，为什么对于存在虚函数的类中析构函数要定义成虚函数**

为了实现多态进行动态绑定，将派生类对象指针绑定到基类指针上，对象销毁时，如果析构函数没有定义为析构函数，则会调用基类的析构函数，显然只能销毁部分数据。如果要调用对象的析构函数，就需要将该对象的析构函数定义为虚函数，销毁时通过虚函数表找到对应的析构函数。

#### 8.2**析构函数能抛出异常吗**

答案肯定是不能。 C++标准指明析构函数不能、也不应该抛出异常。C++异常处理模型最大的特点和优势就是对C++中的面向对象提供了最强大的无缝支持。那么如果对象在运行期间出现了异常，C++异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象(也即对象超出了它原来的作用域)，并释放对象原来所分配的资源， 这就是调用这些对象的析构函数来完成释放资源的任务，所以从这个意义上说，析构函数已经变成了异常处理的一部分。



> (1) 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。
> (2) 通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。

### 9、你理解的==虚函数==和==多态==和==虚函数表==

> 多态的实现主要分为**静态多态**和**动态多态**，静态多态主要是==重载==，在编译的时候就已经确定；动态多态是用==虚函数机制==实现的，在运行期间动态绑定。
>
> 举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数。 虚函数的实现：在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。
>
> 

### 10 ==new/delete与malloc/free==的区别是什么

> 首先，new/delete是**C++的关键字**，而malloc/free是**C语言的库函数**，后者使用必须指明申请内存空间的大小，对于类类型的对象，后者不会调用构造函数和析构函数
>
> 
>
> new分配内存按照数据类型进行分配，malloc分配内存按照大小分配； 
>
> **new不仅分配一段内存，而且会调用构造函数，但是malloc则不会**。new的实现原理？但是还需要注意的是，之前看到过一个题说int *p = new int与int* p = new int()的区别，因为int属于C++内置对象，不会默认初始化，必须显示调用默认构造函数，但是对于自定义对象都会默认调用构造函数初始化。翻阅资料后，在C++11中两者没有区别了，自己测试的结构也都是为0； 
>
> new**返回的是指定对象的指针，而malloc返回的是void***，因此malloc的返回值一般都需要进行类型转化； 
>
> new是一个**操作符可以重载**，malloc是一个**库函数**； 
>
> new分配的内存要用delete销毁，malloc要用free来销毁；delete销毁的时候会调用对象的析构函数，而free则不会； 
>
> malloc分配的**内存不够的时候**，可以用realloc扩容。扩容的原理？new没用这样操作； 
>
> new如果**分配失败**了会抛出bad_malloc的异常，而malloc失败了会返回NULL。因此对于new，正确的姿势是采用try...catch语法，而malloc则应该判断指针的返回值。为了兼容很多c程序员的习惯，C++也可以采用new nothrow的方法禁止抛出异常而返回NULL； 
>
> new和new[]的区别，new[]一次分配所有内存，多次调用构造函数，分别搭配使用delete和delete[]，同理，delete[]多次调用析构函数，销毁数组中的每个对象。而malloc则只能sizeof(int) * n； 
>
> 如果不够可以继续谈new和malloc的实现，空闲链表，分配方法(首次适配原则，最佳适配原则，最差适配原则，快速适配原则)。delete和free的实现原理，free为什么直到销毁多大的空间？

## 二 容器和算法

### 1 ==map和set==的区别，实现方式？

> map和set都是C++的关联容器，其**底层实现都是红黑树**（RB-Tree）。由于 map 和set所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和set的操作行为，都只是转调 RB-tree 的操作行为。
>
> 为什么选用红黑数呢？因为红黑数是平衡二叉树，其插入和删除的效率都是N(logN)，与AVL相比红黑数插入和删除最多只需要3次旋转，而AVL树为了维持其完全平衡性，在坏的情况下要旋转的次数太多。
> 红黑树的定义：
> (1) 节点是红色或者黑色；
> (2) 父节点是红色的话，子节点就不能为红色；
> (3) 从根节点到每个页子节点路径上黑色节点的数量相同；
> (4) 根是黑色的，NULL节点被认为是黑色的。
>
> **map和set区别在于：**
>
> （1）map中的元素是**key-value**（关键字—值）对：关键字起到索引的作用，值则表示与索引相关联的数据；Set与之相对就是关键字的简单集合，set中每个元素只包含一个关键字。
>
> （2）set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key。**其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，**不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。
>
> （3）map支持下标操作，set不支持下标操作。map可以用key做下标，map的下标运算符[ ]将关键码作为下标去执行查找，如果关键码不存在，则插入一个具有该关键码和mapped_type类型默认值的元素至map中，因此下标运算符[ ]在map应用中需要慎用，const_map不能用，只希望确定某一个关键值是否存在而不希望插入元素时也不应该使用，mapped_type类型没有默认值也不应该使用。如果find能解决需要，尽可能用find。

### 2 STL迭代器删除元素

> 这个主要考察的是==迭代器失效的问题==。
>
> 1.对于**序列容器**vector,deque来说，使用erase(itertor)后，后边的每个元素的迭代器都会失效，但是后边每个元素都会往前移动一个位置，但是erase会返回下一个有效的迭代器；
>
> 2.对于**关联容器**map set来说，使用了erase(iterator)后，当前元素的迭代器失效，但是其结构是红黑树，删除当前元素的，不会影响到下一个元素的迭代器，所以在调用erase之前，记录下一个元素的迭代器即可。
>
> 3.对于list来说，它使用了不连续分配的内存，并且它的erase方法也会返回下一个有效的iterator，因此上面两种正确的方法都可以使用。

### 3 STL中map与unordered_map

1、Map

映射，map 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。

底层实现：红黑树

适用场景：有序键值对不重复映射

2、Multimap

多重映射。multimap 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。允许键值重复。

底层实现：红黑树

适用场景：有序键值对可重复映射

### 4 vector和list的区别，应用，越详细越好

> 1）Vector
>
> **连续存储**的容器，**动态数组**，在**堆**上分配空间
>
> 底层实现：数组
>
> 两倍容量增长：
>
> vector 增加（插入）新元素时，如果未超过当时的容量，则还有剩余空间，那么直接添加到最后（插入指定位置），然后调整迭代器。
>
> **如果没有剩余空间了**，则会重新配置原有元素个数的两倍空间，然后将原空间元素通过复制的方式初始化新空间，再向新空间增加元素，最后析构并释放原空间，之前的迭代器会失效。
>
> 性能：
>
> 访问：O(1)
>
> 插入：在最后插入（空间够）：很快;中间慢
>
> 适用场景：经常随机访问，且不经常对非尾节点进行插入删除。
>
> 2、List
>
> **动态链表**，在**堆上**分配空间，每插入一个元数都会分配空间，每删除一个元素都会释放空间。
>
> 底层：双向链表
>
> 性能：
>
> 访问：随机访问性能很差，只能快速访问头尾节点。
>
> 插入：很快，一般是常数开销
>
> 删除：很快，一般是常数开销
>
> 适用场景：经常插入删除大量数据
>
> 3、应用
>
> vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随即访问，而不在乎插入和删除的效率，使用vector。
>
> list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。

### 5 STL中迭代器的作用，有指针为何还要迭代器

> 1、迭代器
>
> Iterator模式是运用于聚合对象的一种模式，通过运用该模式，使得我们可以在不知道对象内部表示的情况下，按照一定顺序（由iterator提供的方法）访问聚合对象中的各个元素。
>
> 2、迭代器和指针的区别
>
> 迭代器不是指针，**是类模板，表现的像指针**。他只是模拟了指针的一些功能，通过重载了指针的一些操作符，->、*、++、--等。迭代器封装了指针，是一个“可遍历STL（ Standard Template Library）容器内全部或部分元素”的对象， 本质是封装了原生指针，是指针概念的一种提升（lift），提供了比指针更高级的行为，相当于一种智能指针，他可以根据不同类型的数据结构来实现不同的++，--等操作。
>
> 迭代器返回的是对象引用而不是对象的值，所以cout只能输出迭代器使用*取值后的值而不能直接输出其自身。
>
> 3、迭代器产生原因
>
> Iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。

### 6 C++中struct和class的区别

> 在C++中，可以用struct和class定义类，都可以继承。区别在于：structural的默认继承权限和默认访问权限是public，而class的默认继承权限和默认访问权限是private。
>
> 但是C中的struct是不同的，函数就不能在C中的struct。
## 三、编译和底层

### 1 编译过程简述

> **预**处理阶段：对源代码文件中文件包含关系（头文件）、预编译语句（宏定义）进行分析和替换，生成预编译文件。.c+.h=>.i//.ii(C++)
>
> **编**译阶段：将经过预处理后的预编译文件转换成特定汇编代码，生成汇编文件 .i=>.s
>
> **汇**编阶段：将编译阶段生成的汇编文件转化成机器码，生成可重定位目标文件 .s=>.o
>
> **链**接阶段：将多个目标文件及所需要的库连接成最终的可执行目标文件      .o =>exe

2 include头文件的顺序以及双引号””和尖括号<>的区别？

> Include头文件的顺序：对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h。那么要在a.c文件中引用b.h文件，并且要先引用b.h，后引用a.h,否则汇报变量类型未声明错误。

> 双引号和尖括号的区别：编译器预处理阶段查找头文件的路径不一样。

> **"当前头文件目录 "**
>
> **编译器设置的头文件路径**（编译器可使用-I显式指定搜索路径）
>
> **系统变量**CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径

### 3 malloc的原理

> Malloc函数用于动态分配内存。为了减少内存碎片和系统调用的开销，malloc其采用**内存池的方式**，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。
>
> 当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。
>
> Malloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。

### 4 C++的==内存管理==是怎样的

![img](https://uploadfiles.nowcoder.com/images/20190313/311436_1552467921124_13956548C4BB199139A2744C39350272)

> 32bitCPU可寻址4G线性空间，每个进程都有各自独立的4G逻辑地址，其中0\~3G是**用户态空间**，3\~4G是**内核空间**，不同进程相同的逻辑地址会映射到不同的物理地址中。其逻辑地址其划分如下：
>
> 各个段说明如下：
>
> 3G用户空间和1G内核空间
>
> 静态区域：
>
> **text segment(代码段)**:包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。
>
> **data segment(数据段)**：存储程序中已初始化的全局变量和静态变量
>
> **bss segment**：存储**未初始化的**全局变量和静态变量（局部+全局），以及**所有被初始化为0**的全局变量和静态变量，对于未初始化的全局变量和静态变量，程序运行main之前时会统一清零。即未初始化的全局变量编译器会初始化为0
>
> 动态区域：
>
> **heap（堆）**： 当进程未调用malloc时是没有堆段的，只有调用malloc时采用分配一个堆，并且在程序运行过程中可以动态增加堆大小(移动break指针)，从低地址向高地址增长。分配小内存时使用该区域。频繁的malloc/free造成内存空间的不连续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。
>
> **memory mapping segment(映射区)**:存储动态链接库等文件映射、申请大内存（malloc时调用mmap函数）
>
> **stack（栈）**：<u>由编译器自动释放，存放函数的参数值、局部变量等</u>。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和临时变量在栈上分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。

### 5 什么是memory leak，也就是内存泄漏

> 内存泄漏(memory leak)是指由于疏忽或错误造成了程序**未能释放掉不再使用的内存**的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。
>
> 内存泄漏的分类：
>
> \1. 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak.
>
> \2. 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
>
> \3. 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

### 6 内存溢出和内存泄漏

**1、内存溢出**

指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误

内存溢出原因：

内存中加载的数据量过于庞大，如一次从数据库取出过多数据

代码中存在死循环或循环产生过多重复的对象实体

启动参数内存值设定的过小

**2、内存泄漏**

内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。

内存泄漏的分类：

1、堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。

2、系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。

3、没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。



### 7内存池

- **STL里的内存池实现**
  STL内存分配分为一级分配器和二级分配器，一级分配器就是采用malloc分配内存，二级分配器采用内存池。

二级分配器设计的非常巧妙，分别给8k，16k,..., 128k等比较小的内存片都维持一个空闲链表，每个链表的头节点由一个数组来维护。需要分配内存时从合适大小的链表中取一块下来。假设需要分配一块10K的内存，那么就找到最小的大于等于10k的块，也就是16K，从16K的空闲链表里取出一个用于分配。释放该块内存时，将内存节点归还给链表。
如果要分配的内存大于128K则直接调用一级分配器。
为了节省维持链表的开销，采用了一个union结构体，分配器使用union里的next指针来指向下一个节点，而用户则使用union的空指针来表示该节点的地址。

## 四：操作系统

### 1 ==进程和线程==(概念、区别、通信)

**基本概念：**

> 进程是对**运行时程序的封装**，是系统进行**资源调度和分配**的的基本单位，实现了操作系统的并发；
>
> 线程是进程的**子任务**，是**CPU调度和分派**的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的**最小执行和调度单位**。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

**区别：**

> 1.一个线程只能**属于**一个进程，而一个进程可以有多个线程，但至少有一个线程。线程**依赖**于进程而存在。
>
> 2.**进程**在执行过程中拥有**独立的内存单元**，而多个**线程共享进程的内存**。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是**每个线程拥有自己的栈段**，栈段又叫运行时段，用来存放所有局部变量和临时变量。）
>
> 3.进程是资源分配的最小单位，线程是CPU调度的最小单位；
>
> 4.**系统开销**： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行**进程切换时**，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而**线程切换**只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。
>
> 5.**通信**：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预
>
> 6.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。
>
> 7.进程间不会**相互影响** ；线程一个线程挂掉将导致整个进程挂掉
>
> 8.进程适应于多核、多机分布；线程适用于多核

**进程间通信的方式：**

> ==进程间通信主要包括**管道**、**系统IPC**（包括消息队列、信号量、信号、共享内存等）、以及**套接字socket**。==
>
> **1.管道：**
>
> 管道主要包括**无名管道**和**命名管道**:管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信
>
> > **1.1 普通管道PIPE：**
> >
> > 1)它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端
> >
> > 2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）
> >
> > 3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
> >
> > **1.2 命名管道FIFO：**
> >
> > 1)FIFO可以在无关的进程之间交换数据
> >
> > 2)FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
> >
> > 
>
> **2. 系统IPC：**
>
> > **2.1 消息队列**
> >
> > 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (**消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点**)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；
> >
> > **特点：**
> >
> > 1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
> >
> > 2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
> >
> > 3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。
> >
> > 
> >
> > **2.2 信号量semaphore**
> >
> > 信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于**实现进程间的互斥与同步，而不是用于存储进程间通信数据。**
> >
> > **特点：**
> >
> > 1)信号量用于**进程间同步**，若要在进程间传递数据需要结合共享内存。
> >
> > 2)信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。
> >
> > 3)每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。
> >
> > 4)支持信号量组。
> >
> > 
> >
> > **2.3 信号signal**
> >
> > 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
> >
> > 
> >
> > **2.4 共享内存（Shared Memory）**
> >
> > 它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等
> >
> > **特点：**
> >
> > 1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取
> >
> > 2)因为多个进程可以同时操作，所以需要进行同步
> >
> > 3)信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问
> >
> > 
>
> 
>
> **3.套接字SOCKET：**
>
> socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。
>
> 

**线程间通信的方式:**

> 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
>
> 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
>
> 信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
>
> 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

#### 1.1 有了==进程==为什么还要==线程==

> **线程产生的原因：**
>
> 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：
>
> <u>进程在同一时间只能干一件事</u>
>
> 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。
>
> 因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。
>
> **和进程相比，线程的优势如下：**
>
> 从资源上来讲，线程是一种非常"节俭"的多任务操作方式。在linux系统下，启动一个新**的进程必须分配给它独立的地址空间**，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式。
>
> **从切换效率上来讲**，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。（
>
> 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。**线程则不然，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便**。
>
> 除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：
>
> 1、使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上。
>
> 2、改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。

#### 1.2僵尸进程

**1）正常进程**

正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。

unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 **但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放**。保存信息包括：

1进程号the process ID

2退出状态the termination status of the process

3运行时间the amount of CPU time taken by the process等

**2）孤儿进程**

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

**3）僵尸进程**

一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。

僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。

如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。

如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

危害：

如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。

外部消灭：

通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源

内部解决：

1、子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。

2、fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。

### 2 ==虚拟地址空间==

**为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。**

虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，<u>在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据</u>。还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。



**虚拟内存的好处：**

**1**.扩大地址空间；

**2.**内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。

3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。

4.当进程通信时，可采用虚存共享的方式实现。

5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存

6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高

**7**.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片



**虚拟内存的代价：**

**1**.虚存的管理需要建立很多**数据结构**，这些数据结构要占用额外的内存

2.虚拟地址到物理地址的**转换**，增加了**指令**的执行时间。

3.页面的换入换出需要**磁盘I/O**，这是很耗时的

4.如果一页中只有一部分数据，会浪费内存。



### 3 缺页中断



malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。**当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。**

**缺页中断**：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1、保护CPU现场

2、分析中断原因

3、转入缺页中断处理程序进行处理

4、恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

1、在指令执行期间产生和处理缺页中断信号

2、一条指令在执行期间，可能产生多次缺页中断

3、缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

### 4 fork和vfork的区别

1.  fork  （）：子进程拷贝父进程的数据段，代码段 
    vfork （ ）：子进程与父进程共享数据段 
2.  fork （）父子进程的执行次序不确定 
    vfork 保证子进程先运行，在调用exec 或exit 之前与父进程数据是共享的,在它调用exec
     或exit 之后父进程才可能被调度运行。 
3.  vfork （）保证子进程先运行，在她调用exec 或exit 之后父进程才可能被调度运行。如果在
   调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。 


> 为什么会有vfork，因为以前的fork 很傻， 它创建一个子进程时，将会创建一个新的地址 空间，并且拷贝父进程的资源，而往往在子进程中会执行exec 调用，这样，前面的拷贝工 作就是白费力气了，这种情况下，聪明的人就想出了vfork，它产生的子进程刚开始暂时与 父进程共享地址空间（其实就是线程的概念了），因为这时候子进程在父进程的地址空间中 运行，所以子进程不能进行写操作，并且在儿子 霸占”着老子的房子时候，要委屈老子一 下了，让他在外面歇着（阻塞），一旦儿子执行了exec 或者exit 后，相 于儿子买了自己的 房子了,这时候就相 于分家了。
>

### 5 虚拟内存置换的方式

 比较常见的内存替换算法有：FIFO，LRU，LFU，LRU-K，2Q。

1、FIFO（先进先出淘汰算法）

思想：最近刚访问的，将来访问的可能性比较大。

实现：使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰。

弊端：无法体现页面冷热信息

2、LFU（最不经常访问淘汰算法）

思想：如果数据过去被访问多次，那么将来被访问的频率也更高。

实现：每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块。

开销：排序开销。

弊端：缓存颠簸。

![img](assets/311436_1552470476683_909843CE326FD7243A252E09C80772B8.png)

3、LRU（最近最少使用替换算法）

思想：如果数据最近被访问过，那么将来被访问的几率也更高。

实现：使用一个栈，新页面或者命中的页面则将该页面移动到栈底，每次替换栈顶的缓存页面。

优点：LRU算法对热点数据命中率是很高的。

缺陷：

1）缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。

2）缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。

4、LRU-K（LRU-2、LRU-3）

思想：最久未使用K次淘汰算法。

LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。

相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。

实现：

1）数据第一次被访问，加入到访问历史列表；

2）如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；

3）当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；

4）缓存数据队列中被再次访问后，重新排序；

5）需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。

针对问题：

LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。

5、2Q

类似LRU-2。使用一个FIFO队列和一个LRU队列。

实现：

1）新访问的数据插入到FIFO队列；

2）如果数据在FIFO队列中一直没有被再次访问，则最终按照FIFO规则淘汰；

3）如果数据在FIFO队列中被再次访问，则将数据移到LRU队列头部；

4）如果数据在LRU队列再次被访问，则将数据移到LRU队列头部；

5）LRU队列淘汰末尾的数据。

针对问题：LRU的缓存污染

弊端：

当FIFO容量为2时，访问负载是：ABCABCABC会退化为FIFO，用不到LRU。

### 6 互斥锁（mutex）机制，以及互斥锁和读写锁的区别

**1、互斥锁和读写锁区别**：

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

**互斥锁和读写锁的区别：**

1）读写锁区分读者和写者，而互斥锁不区分

2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

### 7 进程状态转换图



1、进程的五种基本状态：

![img](assets/311436_1552470678794_F9BF116BD97A95A5E655DF9E1672186F.png)

1）创建状态：进程正在被创建

2）就绪状态：进程被加入到就绪队列中等待CPU调度运行

3）执行状态：进程正在被运行

4）等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行。

5）终止状态：进程运行完毕

2、交换技术

当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0速度比处理机速度慢得多，可能出现全部进程阻塞等待I/O。

针对以上问题，提出了两种解决方法：

1）交换技术：换出一部分进程到外存，腾出内存空间。

2）虚拟存储技术：每个进程只能装入一部分程序和数据。

在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。

从而出现了进**程的挂起状态**：进程被交换到外存，进程状态就成为了挂起状态。



3、活动阻塞，静止阻塞，活动就绪，静止就绪

1）活动阻塞：进程在内存，但是由于某种原因被阻塞了。

2）静止阻塞：进程在外存，同时被某种原因阻塞了。

3）活动就绪：进程在内存，处于就绪状态，只要给CPU和调度就可以直接运行。

4）静止就绪：进程在外存，处于就绪状态，只要调度到内存，给CPU和调度就可以运行。



从而出现了：

活动就绪 ——  静止就绪        （内存不够，调到外存）

活动阻塞 ——  静止阻塞        （内存不够，调到外存）

执行     ——  静止就绪         （时间片用完）



## 五、计算机网络

#### 1 TCP 可靠性，TCP建立连接和断开连接的过程

TCP保证可靠性：

> （1）序列号、确认应答、超时重传
>
> 数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。
>
> （2）窗口控制与高速重发控制/快速重传（重复确认应答）
>
> TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。
>
> 使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒......
>
> （3）拥塞控制
>
> 如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。
>
> 慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2。
>
> 拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1），以此来避免拥塞。
>
> 将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。
>
> 快速重传：在遇到3次重复确认应答（高速重发控制）时，代表收到了3个报文段，但是这之前的1个段丢失了，便对它进行立即重传。
>
> 然后，先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3的大小。
>
> 这样可以达到：在TCP通信时，网络吞吐量呈现逐渐的上升，并且随着拥堵来降低吞吐量，再进入慢慢上升的过程，网络不会轻易的发生瘫痪。



#### 2 三次握手原因：

三次握手是**为了防止，客户端的请求报文在网络滞留**，客户端超时重传了请求报文，服务端建立连接，传输数据，释放连接之后，服务器又收到了客户端滞留的请求报文，建立连接一直等待客户端发送数据。

服务器对客户端的请求进行回应(第二次握手)后，就会理所当然的认为连接已建立，而如果客户端并没有收到服务器的回应呢？此时，客户端仍认为连接未建立，服务器会对已建立的连接保存必要的资源，如果大量的这种情况，服务器会崩溃。

#### 3 TCP释放（四次分手）过程：

> 服务端A：发送FIN报文（FIN = 1），序列号为u（seq = u），进入FIN-WAIT 1状态。
>
> 客户端B：发送ACK确认报文（ACK = 1），序列号为v（seq = v），确认报文u（ack = u + 1），进入CLOSE-WAIT状态，继续传送数据。
>
> 服务端A：收到上述报文进入FIN-WAIT2状态，继续接受B传输的数据。
>
> 客户端B：数据传输完毕后，发送FIN报文（FIN = 1，ACK = 1），序列号为w（seq = w），确认报文u（ack = u + 1），进入LAST-ACK状态。
>
> 服务端A：发送ACK确认报文（ACK = 1），序列号为u+1（seq = u + 1），确认报文w（ack = w + 1），进入TIME-WAIT状态，等待2MSL（最长报文段寿命），进入CLOSED状态。
>
> 客户端B：收到后上述报文后进入CLOSED状态。

#### 4 为什么TCP协议终止链接要四次？

> 1、当客户端确认发送完数据且知道服务器已经接收完了，想要关闭发送数据口（当然确认信号还是可以发），就会发FIN给服务器。
>
> 2、服务器收到客户端发送的FIN，表示收到了，就会发送ACK回复。
>
> 3、但这时候服务器可能还在发送数据，没有想要关闭数据口的意思，所以服务器的FIN与ACK不是同时发送的，而是等到服务器数据发送完了，才会发送FIN给客户端。
>
> 4、客户端收到服务器发来的FIN，知道服务器的数据也发送完了，回复ACK， 客户端等待2MSL以后，没有收到服务器传来的任何消息，知道服务器已经收到自己的ACK了，客户端就关闭链接，服务器也关闭链接了。



#### 5  TCP拥塞控制

拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口——cwnd。

1、慢开始

最开始发送方的拥塞窗口为1，由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮次，拥塞窗口cwnd加倍。当cwnd超过慢开始门限，则使用拥塞避免算法，避免cwnd增长过大。

2、拥塞避免

每经过一个往返时间RTT，cwnd就增长1。

在慢开始和拥塞避免的过程中，一旦发现网络拥塞，就把慢开始门限设为当前值的一半，并且重新设置cwnd为1，重新慢启动。（乘法减小，加法增大）

3、快重传

接收方每次收到一个失序的报文段后就立即发出重复确认，发送方只要连续收到三个重复确认就立即重传（尽早重传未被确认的报文段）。

4、快恢复

当发送方连续收到了三个重复确认，就乘法减半（慢开始门限减半），将当前的cwnd设置为慢开始门限，并且采用拥塞避免算法（连续收到了三个重复请求，说明当前网络可能没有拥塞）。



采用快恢复算法时，慢开始只在建立连接和网络超时才使用。



达到什么情况的时候开始减慢增长的速度？



采用慢开始和拥塞避免算法的时候

\1. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度

\2. 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度

采用快恢复和快重传算法的时候

\1. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度

\2. 一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度

















## XXX 可能问道的题目

#### 1 链表：给定一个单链表的head节点，和K；使k个节点之间一组进行逆序（不能用队列或栈辅助）

例如：
链表:1->2->3->4->5->6->7->8->null, K = 3。那么 6->7->8，3->4->5，1->2各位一组。调整后：1->2->5->4->3->8->7->6->null。其中 1，2不调整，因为不够一组。

**要会递归啊！**

![preview](assets/v2-2ef9dcc38cfdf9fd08e12b1f474fddea_r.jpg)

```cpp
//逆序单链表
list_node* Reverse(list_node* head){
    if(head==NULL || head->next == NULL) return head;
    list_node* result = Reverse(head->next);
    head->next->next = head;
    head->next = NULL;
    return result;
}

list_node* Reverse_K_inorder(list_node* head, int k){
    //找到分治K个节点的尾巴
    list_node* temp = head;
    for(int i=1;i<k&&temp!=NULL;i++){
        temp=temp->next;
    }
    if(temp == NULL) return head;//K太大
    
    //分治下一个节点头t2，暂存
    list_node* t2 = temp->next;//分治下一head
    //尾巴接null
    temp->next = NULL;
    
    //反转K部分，得到新头
    list_node* newhead = Reverse(head);
    //递归分治的，得到缩小范围的头
    list_node* newtemp = Reverse_K_inorder(t2,k);
    //接上
    head->next = newtemp;
    
    return newhead;
}



//如果是从尾部开始K个一组？？？？先反以下咯
list_node * reverse_k_back_(list_node * head, int k)
{
    head = Reverse(head);
    // 调用每 k 个为一组的逆序函数（从头部开始组起）
    head = Reverse_K_inorder(head, k);
    // 在逆序一次
    head = Reverse(head);
    return head;
}
```


#### 2 矩阵: 有序的二维数组找目标

在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。

```cpp
 bool Find(int target, vector<vector<int> > array) {
        int row = array.size();
        int col = array[0].size();
        int a=0;
        int b=col-1;
        while(a<=row-1&&b>=0){
            if(array[a][b]==target){
                return true;
            }else if(array[a][b]<target){
                //小于目标数就往下
                a++;
               continue;
            }else{
                //大于目标数，说明该列都大于，就往左走
                b--;
                continue;
            }
        }
        return false;
        
    }
```

#### 

# 排序

## 堆排序

堆可以用数组来表示，这是因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。这里不使用数组索引为 0 的位置，是为了更清晰地描述节点的位置关系。

```cpp
//上浮，构建最大堆 适合i=0--n 进行上浮
void swim(int k) {
    while (k > 1 && less(k / 2, k)) {
        swap(k / 2, k);
        k = k / 2;
    }
}


无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。

//下沉，将index节点下沉到合适的底部
void adjust(vector<int> &arr, int len, int index)
{
    //len限制调整到的规模
    int left = 2*index + 1; // index的左子节点
    int right = 2*index + 2;// index的右子节点
 
    int maxIdx = index;
    if(left<len && arr[left] > arr[maxIdx])     maxIdx = left;
    if(right<len && arr[right] > arr[maxIdx])     maxIdx = right;
 	
    //相对最大的节点不是根节点就swap，递归下去调制 上浮
    if(maxIdx != index)
    {
        swap(arr[maxIdx], arr[index]);
        adjust(arr, len, maxIdx);
    }
 
}

void heapSort(vector<int> &arr, int size)
{
    //优势就是不用单独再对叶子阶段进行操作
    // 构建大根堆（从最后一个非叶子节点向上），一个个上浮
    for(int i=size/2 - 1; i >= 0; i--)
    {
        adjust(arr, size, i);
    }
 
    // 调整大根堆
    for(int i = size - 1; i >= 1; i--)
    {
        swap(arr[0], arr[i]);           // 将当前最大的放置到数组末尾
        adjust(arr, i, 0);              // 将未完成排序的部分继续进行堆排序
    }
}
```







## 插入排序



```cpp
 void sort(T[] nums) {
        int N = nums.length;
        for (int i = 1; i < N; i++) {//每一个都要考虑到
            for (int j = i; j > 0 && nums[j]< nums[j - 1]; j--) {//往前，小就交换
                swap(nums, j, j - 1);
            }
        }
    }
```

## 希尔排序

分批插入排序

```cpp
  public void sort(T[] nums) {

        int N = nums.length;
        int h = 1;

        while (h < N / 3) {
            h = 3 * h + 1; // 1, 4, 13, 40, ...
        }

        while (h >= 1) {
            for (int i = h; i < N; i++) {
                for (int j = i; j >= h && nums[j]< nums[j - h]; j -= h) {
                    swap(nums, j, j - h);
                }
            }
            h = h / 3;
        }
    }
```





## 快排

1 切分，pivot为key，小的左边，大的右边

```cpp
int partition(T[] nums, int l, int h) {
    int i = l, j = h + 1;
    T v = nums[l];//这里以第一个为pivot
    while (true) {
        while (nums[++i] < v && i != h) ;//左边第一个大于pivot的地方i
        while (v < nums[--j] && j != l) ;//右边第一个小于pivot的地方j
        if (i >= j)
            break;
        swap(nums, i, j);
    }
    //结束后把pivot放到合适的地方，i>v;j<v;所以v要和j换
    swap(nums, l, j);
    return j;
}
```



```cpp
 public void sort(T[] nums) {
        shuffle(nums);
        sort(nums, 0, nums.length - 1);
    }

    private void sort(T[] nums, int l, int h) {
        if (h <= l)
            return;
        int j = partition(nums, l, h);
        sort(nums, l, j - 1);
        sort(nums, j + 1, h);
    }
```













## 对比分析

| 算法             | 稳定性 | 时间复杂度                   | 空间复杂度 | 备注                     |
| ---------------- | ------ | ---------------------------- | ---------- | ------------------------ |
| 选择排序         | ×      | N2                           | 1          |                          |
| 冒泡排序         | √      | N2                           | 1          |                          |
| 插入排序         | √      | N ~ N2                       | 1          | 时间复杂度和初始顺序有关 |
| 希尔排序         | ×      | N 的若干倍乘于递增序列的长度 | 1          | 改进版插入排序           |
| 快速排序         | ×      | NlogN                        | logN       |                          |
| 三向切分快速排序 | ×      | N ~ NlogN                    | logN       | 适用于有大量重复主键     |
| 归并排序         | √      | NlogN                        | N          |                          |
| 堆排序           | ×      | NlogN                        | 1          | 无法利用局部性原理       |



 

# 树_生成树\_递归&非递归遍历

```
第一行输入两个整数 n 和 root，n 表示二叉树的总节点个数，root 表示二叉树的根节点。以下 n 行每行三个整数 fa，lch，rch，表示 fa 的左儿子为 lch，右儿子为 rch。(如果 lch 为 0 则表示 fa 没有左儿子，rch同理)
```

输入树的样式：

```
3 1
1 2 3
2 0 0
3 0 0
```

```cpp
#include "stdafx.h"
#include <iostream>
#include <vector>

using namespace std;


struct Node {
	int val;
	Node* left;
	Node* right;
	Node(int value) {
		this->val = value;
		this->left = NULL;
		this->right = NULL;
	}
};

/******递归的方法**************/
void Preorder_Recure(Node* head) {
	//出口
	if (head == NULL) return;

	cout << head->val << " ";
	Preorder_Recure(head->left);
	Preorder_Recure(head->right);
}

void Inorder_Recure(Node* head) {
	//出口
	if (head == NULL) return;

	Inorder_Recure(head->left);
	cout << head->val << " ";
	Inorder_Recure(head->right);
}

void Posorder_Recure(Node* head) {
	//出口
	if (head == NULL) return;

	Posorder_Recure(head->left);
	Posorder_Recure(head->right);
	cout << head->val << " ";
}



/*****************************/

/*********非递归方法*********************/
/*
stack head
while(!empty)
    op->cur
    if(r!=null) push
    if(l!=null) push*/
void Preorder_UnRec(Node *head){
    if(head!=NULL){
        stack<Node*> stack;
        stack.push(head);///////////stack先方个头
        while(!stack.empty()){
            Node* cur = stack.top();stack.pop();
            cout<<cur->val<<" ";
            if(cur->right!=NULL) stack.push(cur->right);//////!!!right 先
            if(cur->left!=NULL) stack.push(cur->left);
        }
    }
}

//中序非递归
void Inorder_UnRec(Node* head){
    if(head!=NULL){
        stack<Node*> stack;
        while(!stack.empty()|| head!=NULL){
            if(head!=NULL){//左边界全压栈到底
                stack.push(head);
                head = head->left;
            }else{
                head = stack.top();stack.pop();//左边界叶子op，完事看看右边树
                cout<<head->val<<" ";
                head = head->right;
            }
        }
    }
}

///后序非递归
void Posorder_UnRec(Node* head){
    if(head!=NULL){
        stack<Node*> s1;
        stack<Node*> s2;
        s1.push(head);
        while(!s1.empty()){
            Node* cur = s1.top();s1.pop();
            s2.push(cur);
            if(cur->left!=NULL) s1.push(cur->left);
            if(cur->right!=NULL) s1.push(cur->right);
        }
        
        while(!s2.empty()){
            cout<<s2.top()->val<<" ";
            s2.pop();
        }
    }
    
}


/************************************************/


int main() {
	freopen("DATA.txt", "r", stdin);
	int n, root;
	cin >> n;
	vector<Node*> arr(n + 1, 0);
	
	cin >> root;

	Node * tree = (Node*)malloc(sizeof(Node));
	tree->val=root;
	tree->left = NULL;
	tree->right = NULL;
	arr[root] = tree;
	Node* node = tree;
	for (int i = 0; i<n; i++) {
		int a, b, c;
		cin >> a >> b >> c;

		node = arr[a];//先看看输入的这个节点存在否
		if (node!=NULL) {
			if (b != 0) {
				//如果左子树不是NULL
				if (arr[b] == NULL) {//且不存在，就创建
					node->left = (Node*)malloc(sizeof(Node));
					node->left->val = b;
					node->left->left = NULL;
					node->left->right = NULL;
					arr[b] = node->left;
				}
				else {//左子树存在就接上
					node->left = arr[b];
				}
				
			}
			else if(b==0) {
				node->left = NULL;
			}

			if (c != 0) {
				//如果左子树不是NULL
				if (arr[c] == NULL) {//且不存在，就创建
					node->right = (Node*)malloc(sizeof(Node));
					node->right->val = c;
					node->right->left = NULL;
					node->right->right = NULL;
					arr[c] = node->right;
				}
				else {//左子树存在就接上
					node->right = arr[c];
				}

			}
			else if (c == 0) {
				node->right = NULL;
			}
		}
		else {
			//新告诉的节点不是已知的节点信息
			Node* temp = (Node*)malloc(sizeof(Node));
			arr[a] = temp;
			temp->val = a;

			node = arr[a];//先看看输入的这个节点存在否
			if (node != NULL) {
				if (b != 0) {
					//如果左子树不是NULL
					if (arr[b] == NULL) {//且不存在，就创建
						node->left = (Node*)malloc(sizeof(Node));
						node->left->val = b;
						node->left->left = NULL;
						node->left->right = NULL;
						arr[b] = node->left;
					}
					else {//左子树存在就接上
						node->left = arr[b];
					}

				}
				else if (b == 0) {
					node->left = NULL;
				}

				if (c != 0) {
					//如果左子树不是NULL
					if (arr[c] == NULL) {//且不存在，就创建
						node->right = (Node*)malloc(sizeof(Node));
						node->right->val = c;
						node->right->left = NULL;
						node->right->right = NULL;
						arr[c] = node->right;
					}
					else {//左子树存在就接上
						node->right = arr[c];
					}

				}
				else if (c == 0) {
					node->right = NULL;
				}
			}
		}
	}

	Preorder_Recure(tree); cout << endl;
	Inorder_Recure(tree); cout << endl;
	Posorder_Recure(tree);

}
```

### 约瑟夫环\_数组_

```cpp
int y(int n,int m)
{
	int i,j=0,s=0,l;
	int *a=(int *)malloc(sizeof(int));
	int *b=(int *)malloc(sizeof(int));
	for(i=0;i<n;i++)
	{
		a[i]=i+1;
	}
	a[n]=-1;
	for(i=0;j!=n;i++)
	{
		if(a[i]==-1) 
			i=0;
		if(a[i]!=0 && a[i]!=-1)
			s++;
		if(s==m)
		{
			b[j]=a[i];
			a[i]=0;
			j++;
			s=0;
		}
	}
	for(i=0;i<n;i++)
	{
		printf("%5d",b[i]);
	}
	printf("\n");
	l=b[n-1];
	return l;
}

```



